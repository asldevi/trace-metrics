version: "2.4"
services:
  app:
    build: .
    ports:
      - 8080:8080
    # depends_on:
    #   - jaeger
    environment:
      - JAEGER_AGENT_HOST=jaeger-agent
      - JAEGER_AGENT_PORT=6831
    # networks:
    #   - trace-metrics

  httpbin:
    image: kennethreitz/httpbin
    ports:
      - 8081:80
    # networks:
    #   - trace-metrics

  prometheus:
    image: prom/prometheus
    ports:
      - 9090:9090
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    depends_on:
      -  app
    # networks:
    #   - trace-metrics

  # jaeger:
  #   image: jaegertracing/all-in-one:latest
  #   ports:
  #     - "6831:6831/udp"
  #     - "16686:16686"
  #   networks:
  #     - trace-metrics

  grafana:
    image: grafana/grafana
    ports:
      - 3001:3000
    # networks:
    #   - trace-metrics

  hypertrace:
    image: hypertrace/hypertrace:main
    container_name: hypertrace
    environment:
      - MONGO_HOST=mongo
      - ZK_CONNECT_STR=zookeeper:2181/hypertrace-views
    ports:
      - 2020:2020
    healthcheck:
      start_period: 20s
    depends_on:
      mongo:
        condition: service_healthy
      kafka-zookeeper:
        condition: service_healthy
      pinot:
        condition: service_started

  # Ingestion pipeline
  otel-collector:
    image: otel/opentelemetry-collector-dev:latest
    command: ["/otelcol", "--config=/etc/otel-collector-config.yaml", "--mem-ballast-size-mib=683"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317"        # OTLP gRPC receiver
      - "55670:55679" # zpages extension
      - "14250:14250"
    depends_on:
      kafka-zookeeper:
        condition: service_healthy
        #- jaeger-all-in-one
        #- zipkin-all-in-one

  jaeger-agent:
    image: jaegertracing/jaeger-agent:1.21
    #command: ["--reporter.grpc.host-port=jaeger-collector:14250", "--log-level=debug"]
    command: ["--reporter.grpc.host-port=otel-collector:14250", "--log-level=debug"]
    ports:
        - "5775:5775/udp"
        - "6831:6831/udp"
        - "6832:6832/udp"
        - "5778:5778"
    restart: on-failure
    depends_on:
      #jaeger-collector:
        #condition: service_started
      otel-collector:
        condition: service_started
  
  hypertrace-ingester:
    image: hypertrace/hypertrace-ingester
    container_name: hypertrace-ingester
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - DEFAULT_TENANT_ID=__default
      - SPAN_GROUPBY_SESSION_WINDOW_INTERVAL=2
      - REPLICATION_FACTOR=1
      - ENTITY_SERVICE_HOST_CONFIG=hypertrace
      - ENTITY_SERVICE_PORT_CONFIG=9001
      - ATTRIBUTE_SERVICE_HOST_CONFIG=hypertrace
      - ATTRIBUTE_SERVICE_PORT_CONFIG=9001
      - CONFIG_SERVICE_HOST_CONFIG=hypertrace
      - CONFIG_SERVICE_PORT_CONFIG=9001
      - NUM_STREAM_THREADS=1
      - PRE_CREATE_TOPICS=true
      - PRODUCER_VALUE_SERDE=org.hypertrace.core.kafkastreams.framework.serdes.GenericAvroSerde
    volumes:
      - ../docker/configs/log4j2.properties:/app/resources/log4j2.properties:ro
    depends_on:
      kafka-zookeeper:
        condition: service_healthy
      hypertrace:
        # service_started, not service_healthy as pinot and deps can take longer than 60s to start
        condition: service_started

# Third-party data services:

  # Kafka is used for streaming functionality.
  # ZooKeeper is required by Kafka and Pinot
  kafka-zookeeper:
    image: hypertrace/kafka-zookeeper:main
    container_name: kafka-zookeeper
    networks:
      default:
        # prevents apps from having to use the hostname kafka-zookeeper
        aliases:
          - kafka
          - zookeeper
  # Stores entities like API, service and backend
  mongo:
    image: hypertrace/mongodb:main
    container_name: mongo
  # Stores spans and traces and provides aggregation functions
  pinot:
    image: hypertrace/pinot-servicemanager:main
    container_name: pinot
    environment:
      - LOG_LEVEL=error
    networks:
      default:
        # Usually, Pinot is distributed, and clients connect to the controller
        aliases:
          - pinot-controller
          - pinot-server
          - pinot-broker
    cpu_shares: 2048
    depends_on:
      kafka-zookeeper:
        condition: service_healthy
    


# networks:
#   trace-metrics:

